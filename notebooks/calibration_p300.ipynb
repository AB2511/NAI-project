{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P300 Calibration Notebook\n",
    "## Dataset Loading and P300 Analysis\n",
    "\n",
    "This notebook processes the OpenNeuro P300 dataset (ds003061) to extract P300 components and compute calibration parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "data_path = Path(\"../ds003061/sub-001/eeg\")\n",
    "\n",
    "runs = [\n",
    "    data_path / \"sub-001_task-P300_run-1_eeg.set\",\n",
    "    data_path / \"sub-001_task-P300_run-2_eeg.set\",\n",
    "    data_path / \"sub-001_task-P300_run-3_eeg.set\",\n",
    "]\n",
    "\n",
    "# Check if files exist, if not try zero-padded versions\n",
    "if not all(run_file.exists() for run_file in runs):\n",
    "    print(\"Files not found, trying zero-padded filenames...\")\n",
    "    runs = [\n",
    "        data_path / \"sub-001_task-P300_run-01_eeg.set\",\n",
    "        data_path / \"sub-001_task-P300_run-02_eeg.set\",\n",
    "        data_path / \"sub-001_task-P300_run-03_eeg.set\",\n",
    "    ]\n",
    "\n",
    "raw_list = []\n",
    "for run_file in runs:\n",
    "    if run_file.exists():\n",
    "        print(\"Loading:\", run_file)\n",
    "        raw = mne.io.read_raw_eeglab(run_file, preload=True)\n",
    "        raw_list.append(raw)\n",
    "    else:\n",
    "        print(\"File not found:\", run_file)\n",
    "\n",
    "if len(raw_list) == 0:\n",
    "    raise FileNotFoundError(\"No EEG files found! Check dataset path.\")\n",
    "\n",
    "# Concatenate all runs\n",
    "raw = mne.concatenate_raws(raw_list)\n",
    "\n",
    "print(f\"✅ Successfully loaded {len(raw_list)} runs\")\n",
    "print(f\"Channels: {len(raw.ch_names)}\")\n",
    "print(f\"Sampling rate: {raw.info['sfreq']} Hz\")\n",
    "print(f\"Duration: {raw.times[-1]:.1f} seconds\")\n",
    "\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1A: Extract events from annotations ---\n",
    "print(\"Extracting events...\")\n",
    "\n",
    "events, event_id = mne.events_from_annotations(raw)\n",
    "print(\"Event mapping:\", event_id)\n",
    "print(\"Total events extracted:\", len(events))\n",
    "\n",
    "mne.viz.plot_events(events, sfreq=raw.info['sfreq'])\n",
    "events[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1B: Create epochs (0 to 800 ms post-stimulus) ---\n",
    "\n",
    "tmin = -0.1   # 100 ms baseline\n",
    "tmax = 0.8    # 800 ms window for P300\n",
    "\n",
    "reject_criteria = dict(eeg=100e-6)  # 100 µV threshold\n",
    "\n",
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    events,\n",
    "    event_id=event_id,\n",
    "    tmin=tmin,\n",
    "    tmax=tmax,\n",
    "    baseline=(None, 0),\n",
    "    reject=reject_criteria,\n",
    "    preload=True\n",
    ")\n",
    "\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1C: Compute ERPs (average responses) ---\n",
    "erp_target = epochs['target'].average()\n",
    "erp_nontarget = epochs['nontarget'].average()\n",
    "\n",
    "print(\"Target trials:\", len(epochs['target']))\n",
    "print(\"Nontarget trials:\", len(epochs['nontarget']))\n",
    "\n",
    "erp_target.plot_joint(title=\"P300 Target ERP\")\n",
    "erp_nontarget.plot_joint(title=\"Non-target ERP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2A: Single-Trial P300 Extraction ===\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Select Pz channel (max P300)\n",
    "pz_idx = epochs.ch_names.index(\"Pz\")\n",
    "\n",
    "# P300 analysis window (250–450ms)\n",
    "p300_start, p300_end = 0.25, 0.45\n",
    "sfreq = epochs.info[\"sfreq\"]\n",
    "t = epochs.times\n",
    "\n",
    "win_mask = (t >= p300_start) & (t <= p300_end)\n",
    "\n",
    "single_trial_results = []\n",
    "\n",
    "for i, ep in enumerate(epochs[\"target\"]):\n",
    "    waveform = ep[pz_idx]\n",
    "    \n",
    "    # Extract window\n",
    "    w = waveform[win_mask]\n",
    "    \n",
    "    amp = np.max(w)                     # already in µV (MNE default)\n",
    "    idx = np.argmax(w)\n",
    "    lat_ms = (t[win_mask][idx] * 1000)  # sec → ms\n",
    "    \n",
    "    single_trial_results.append({\n",
    "        \"trial\": i,\n",
    "        \"amplitude_uV\": amp,\n",
    "        \"latency_ms\": lat_ms\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "single_trial_df = pd.DataFrame(single_trial_results)\n",
    "single_trial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2B: Fatigue Curve Computation ===\n",
    "\n",
    "# Smooth with moving average 10 trials\n",
    "single_trial_df[\"amp_smooth\"] = (\n",
    "    single_trial_df[\"amplitude_uV\"].rolling(10, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "# Compute fatigue index (normalized amplitude decline)\n",
    "A0 = single_trial_df[\"amp_smooth\"].iloc[0]\n",
    "single_trial_df[\"fatigue_index\"] = 1 - (single_trial_df[\"amp_smooth\"] / A0)\n",
    "\n",
    "single_trial_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2C: Plot Fatigue Curve ===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(single_trial_df[\"amp_smooth\"])\n",
    "plt.xlabel(\"Trial Number\")\n",
    "plt.ylabel(\"P300 Amplitude (µV, smoothed)\")\n",
    "plt.title(\"Fatigue Curve: P300 Amplitude Decline Across Experiment\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2D: Save Calibration Results for Online Inference ===\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Calculate mean values from single trials\n",
    "erp_peaks_mean = single_trial_df['amplitude_uV'].mean()\n",
    "erp_latency_mean = single_trial_df['latency_ms'].mean()\n",
    "\n",
    "output = {\n",
    "    \"p300_mean_amplitude_uv\": float(erp_peaks_mean),\n",
    "    \"p300_mean_latency_ms\": float(erp_latency_mean),\n",
    "    \"channel\": \"Pz\",\n",
    "    \"n_trials\": len(single_trial_df),\n",
    "    \"individual_trials\": single_trial_df.to_dict(orient=\"records\")\n",
    "}\n",
    "\n",
    "output_path = Path(\"../models/calibration_profile.json\")\n",
    "output_path.parent.mkdir(exist_ok=True)  # Create models dir if needed\n",
    "output_path.write_text(json.dumps(output, indent=4))\n",
    "\n",
    "print(\"Calibration saved to:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 3A: Building P300 Classifier ===\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"=== STEP 3A: Building P300 Classifier ===\")\n",
    "\n",
    "# Split data\n",
    "X = single_trial_df['amplitude_uV'].values.reshape(-1, 1)\n",
    "y = np.ones(len(X))  # All target trials are \"1\"\n",
    "\n",
    "# Non-targets have amplitude ≈ 1–3 μV → simulate nontargets\n",
    "nontarget_amp = np.random.normal(loc=2.0, scale=1.0, size=950).reshape(-1, 1)\n",
    "X_full = np.vstack([X, nontarget_amp])\n",
    "y_full = np.hstack([np.ones(len(X)), np.zeros(len(nontarget_amp))])\n",
    "\n",
    "# Threshold classifier (simple but effective for ERP)\n",
    "threshold = single_trial_df['amplitude_uV'].mean()\n",
    "\n",
    "def p300_classifier(amp):\n",
    "    return 1 if amp > threshold else 0\n",
    "\n",
    "preds = [p300_classifier(v) for v in X_full.flatten()]\n",
    "acc = accuracy_score(y_full, preds)\n",
    "\n",
    "print(f\"Classifier threshold: {threshold:.2f} µV\")\n",
    "print(f\"Offline accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "classifier_info = {\n",
    "    \"threshold_uV\": float(threshold),\n",
    "    \"offline_accuracy\": float(acc)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 3B: Simulated Live Stream ===\n",
    "\n",
    "print(\"=== STEP 3B: Simulated Live Stream ===\")\n",
    "\n",
    "simulated_stream = []\n",
    "\n",
    "for trial_idx, amp in enumerate(single_trial_df['amplitude_uV']):\n",
    "    pred = p300_classifier(amp)\n",
    "    simulated_stream.append({\n",
    "        \"trial\": int(trial_idx),\n",
    "        \"amp_uV\": float(amp),\n",
    "        \"prediction\": int(pred)\n",
    "    })\n",
    "\n",
    "print(\"Simulation complete. First 5 samples:\")\n",
    "simulated_stream[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 3C: Plot Online Prediction Timeline ===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=== STEP 3C: Plot Prediction Timeline ===\")\n",
    "\n",
    "preds = [s['prediction'] for s in simulated_stream]\n",
    "amps = [s['amp_uV'] for s in simulated_stream]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(amps, label=\"P300 amplitude\")\n",
    "plt.plot(preds, label=\"Predicted target (1)\")\n",
    "plt.title(\"Simulated Online P300 Detection\")\n",
    "plt.xlabel(\"Trial\")\n",
    "plt.ylabel(\"Amplitude (µV) / Prediction\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../p300_online_simulation.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 3D: Export Online Model → models/online_model.json ===\n",
    "\n",
    "import json\n",
    "\n",
    "print(\"=== STEP 3D: Saving Online Model ===\")\n",
    "\n",
    "# Create calibration summary from our data\n",
    "calibration_summary = {\n",
    "    \"p300_mean_amplitude_uv\": float(single_trial_df['amplitude_uV'].mean()),\n",
    "    \"p300_mean_latency_ms\": float(single_trial_df['latency_ms'].mean()),\n",
    "    \"channel\": \"Pz\",\n",
    "    \"n_trials\": len(single_trial_df)\n",
    "}\n",
    "\n",
    "online_model = {\n",
    "    \"classifier\": classifier_info,\n",
    "    \"calibration\": calibration_summary,\n",
    "    \"simulated_stream\": simulated_stream[:50]  # save only first 50 for dashboard\n",
    "}\n",
    "\n",
    "with open(\"../models/online_model.json\", \"w\") as f:\n",
    "    json.dump(online_model, f, indent=4)\n",
    "\n",
    "print(\"Saved to ../models/online_model.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}