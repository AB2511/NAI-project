% Camera-ready for Springer CCIS / LNCS (llncs.cls)
\documentclass[runningheads]{llncs}

\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{float}
\usepackage{microtype}
\usepackage{url}
\usepackage{hyperref}

% Metadata
\begin{document}

\title{NeuroAdaptive Interface (NAI): Real-Time P300 Detection and Cognitive-State Monitoring using EEGNet and Cross-Subject Evaluation}
\titlerunning{NeuroAdaptive Interface (NAI)}

\author{Anjali Barge\inst{1}\orcidID{0009-0005-1983-9214}\thanks{Corresponding author: \texttt{bargeanjali650@gmail.com}}}
\authorrunning{A. Barge}

\institute{Alard College of Engineering and Management (Affiliated to Savitribai Phule Pune University), Pune, India \\
\email{bargeanjali650@gmail.com}}

\maketitle

\begin{abstract}
I present the NeuroAdaptive Interface (NAI), an end-to-end real-time brain–computer interface pipeline for P300-based cognitive-state monitoring. The system integrates Lab Streaming Layer (LSL) acquisition, ERP preprocessing, EEGNet inference, and an adaptive Streamlit dashboard. Evaluation on the ERP CORE P3b dataset (20 subjects) using Leave-One-Subject-Out (LOSO) cross-validation yields a cross-subject AUC of $0.57 \pm 0.08$, while within-subject AUC reaches $0.85$--$0.90$. I provide electrophysiological analyses (grand-average ERPs, difference waves, topographies) and publication-quality figures derived from real data to demonstrate both feasibility and the limitations of cross-subject neuroadaptive systems.
\keywords{EEG \and P300 \and BCI \and EEGNet \and LOSO \and ERP CORE}
\end{abstract}

\section{Introduction}
The P300 event-related potential (ERP) is a robust neural marker of stimulus-related cognitive processing \cite{sutton1965p300,farwell1988talking}. P300-based brain–computer interfaces (BCIs) are widely used for communication and cognitive monitoring, but cross-subject generalization remains challenging due to large inter-subject variability in amplitude, latency, and noise characteristics \cite{krusienski2006comparison}. Deep learning architectures designed for EEG, such as EEGNet \cite{lawhern2018eegnet}, offer compact, data-efficient models for ERP classification.

In this work I build and evaluate a production-style, real-time pipeline (acquisition → preprocessing → inference → dashboard). I focus on honest, reproducible reporting of cross-subject performance using a strict LOSO protocol on the ERP CORE P3b dataset \cite{kappenman2021erp}, and I contrast cross-subject performance with within-subject results.

\section{Methods}

\subsection{System overview}
The NAI pipeline (Fig.~\ref{fig:architecture}) comprises:
\begin{enumerate}
  \item EEG acquisition via LSL,
  \item preprocessing and epoching (ERP pipeline),
  \item EEGNet inference for P300 detection,
  \item lightweight cognitive-state mapping and Streamlit dashboard for real-time feedback.
\end{enumerate}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\textwidth]{final/system_architecture.png}
  \caption{NAI system architecture: acquisition, preprocessing, inference, and dashboard.}
  \label{fig:architecture}
\end{figure}

\subsection{Dataset}
I used the ERP CORE P3b dataset \cite{kappenman2021erp} (OpenNeuro ds003061). For reproducibility, I followed the dataset BIDS layout and preprocessing recommendations from the release. For the subset used here the per-subject trial counts were typical of P3b oddball paradigms (≈80 targets, ≈320 non-targets).

\subsection{Preprocessing}
Preprocessing was performed with MNE-Python \cite{gramfort2013mne} using standard ERP procedures:
\begin{itemize}
  \item band-pass filter: 0.1--15\,Hz,
  \item epoch window: $[-200,800]$\,ms around stimulus onset,
  \item baseline correction: $[-200,0]$\,ms,
  \item artifact rejection (peak-to-peak thresholds), and average referencing.
\end{itemize}
I computed grand-average ERPs and difference waves (target minus non-target) and generated topographic maps at the P3b peak.

\subsection{Model and training}
I implemented EEGNet \cite{lawhern2018eegnet} with typical compact configuration (temporal convolution, depthwise separable filters, batch norm, dropout). Training details:
\begin{itemize}
  \item optimizer: Adam;
  \item loss: binary cross-entropy;
  \item regularization: dropout 0.3 and early stopping on validation AUC;
  \item LOSO: 20 folds (train on 19 subjects, test on 1);
  \item within-subject: per-subject 80/20 split for comparison.
\end{itemize}

\subsection{Evaluation metrics}
Primary metric: Area Under the ROC Curve (AUC). I report mean and standard deviation across LOSO folds. For clarity and reproducibility, I provide the scripts used to reproduce these metrics in the repository.

\section{Results}

\subsection{Neurophysiology}
Figure~\ref{fig:erp_topo} shows the grand-average ERP at Pz and the topographic map at the P3b peak. The difference wave (target minus non-target) isolates the P3b component with expected parietal maximum.

\begin{figure}[H]
  \centering
  \begin{subfigure}{0.48\textwidth}
    \includegraphics[width=\textwidth]{final/erp_grand_target_vs_nontarget.png}
    \caption{Grand-average ERP at Pz}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\textwidth}
    \includegraphics[width=\textwidth]{final/topomap_group_peak.png}
    \caption{Topographic map at P300 peak}
  \end{subfigure}
  \caption{ERP and topography demonstrating the P3b response (figures derived from ERP CORE P3b data after preprocessing).}
  \label{fig:erp_topo}
\end{figure}

\subsection{Classification performance}
Table~\ref{tab:auc} summarizes performance. The LOSO cross-subject AUC is $0.57 \pm 0.08$, reflecting the difficulty of subject-independent P300 decoding. Within-subject AUC (per-subject 80/20) is substantially higher ($0.85$--$0.90$), demonstrating the model's capacity when individualized.

\begin{table}[H]
\centering
\caption{Classification summary (AUC).}\label{tab:auc}
\begin{tabular}{lcc}
\toprule
Method & AUC & Setting \\
\midrule
EEGNet (LOSO) & $0.57 \pm 0.08$ & cross-subject (20-fold LOSO) \\
EEGNet (within-subject) & $0.85$--$0.90$ & per-subject (80/20 split) \\
\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:classification} shows the LOSO ROC curve and the confusion matrix aggregated across folds.

\begin{figure}[H]
  \centering
  \begin{subfigure}{0.48\textwidth}
    \includegraphics[width=\textwidth]{final/roc_eegnet_loso.png}
    \caption{ROC (LOSO)}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.48\textwidth}
    \includegraphics[width=\textwidth]{final/confusion_matrix_group.png}
    \caption{Confusion matrix (aggregated)}
  \end{subfigure}
  \caption{LOSO cross-validation results.}
  \label{fig:classification}
\end{figure}

\subsection{Discussion of results}
The observed LOSO AUC of 0.57 is consistent with published baselines for strict cross-subject ERP decoding (commonly 0.55--0.65). This outcome underscores the large inter-subject variability in ERP features (amplitude, latency, scalp distribution) and the need for subject-specific calibration or adaptive transfer-learning methods for deployable BCI systems. The high within-subject performance (0.85--0.90) confirms that the architecture itself can learn discriminative features when trained on the same subject.

\section{Conclusion}
I present NAI as a reproducible, real-time-ready pipeline for P300 detection and cognitive-state monitoring. The system demonstrates the practical trade-off between cross-subject generalization and within-subject performance and provides a strong baseline for future transfer-learning or personalization work.

\section*{Acknowledgments}
I thank Prof. Anoop Kushwaha (HOD, Computer Engineering), Prof. Manali S. Patil, and Prof. Vrushali More (Alard College of Engineering \& Management) for mentorship and support during this project. I used the ERP CORE (OpenNeuro ds003061) dataset; full credit to the dataset authors.

\section*{Data Availability}
All code, preprocessing scripts, and publication-quality figures are available in the project repository: \url{https://github.com/AB2511/NAI-project}. The ERP CORE dataset is available from OpenNeuro (ds003061) under its original license and must be downloaded separately by readers.

\section*{Disclosure of Interests}
The author declares no competing interests relevant to this manuscript.

\clearpage
% ---- Bibliography ----
\bibliographystyle{splncs04}
\begin{thebibliography}{10}

\bibitem{sutton1965p300}
Sutton, S., Braren, M., Zubin, J., John, E.R.:
Evoked-potential correlates of stimulus uncertainty.
Science \textbf{150}(3700), 1187--1188 (1965)

\bibitem{farwell1988talking}
Farwell, L.A., Donchin, E.:
Talking off the top of your head: toward a mental prosthesis utilizing event-related brain potentials.
Electroencephalography and Clinical Neurophysiology \textbf{70}(6), 510--523 (1988)

\bibitem{krusienski2006comparison}
Krusienski, D.J., et~al.:
A comparison of classification techniques for the P300 Speller.
Journal of Neural Engineering \textbf{3}(4), 299--305 (2006)

\bibitem{lawhern2018eegnet}
Lawhern, V.J., Solon, A.J., Waytowich, N.R., Gordon, S.M., Hung, C.P., Lance, B.J.:
EEGNet: a compact convolutional neural network for EEG-based brain–computer interfaces.
Journal of Neural Engineering \textbf{15}(5), 056013 (2018). \url{https://doi.org/10.1088/1741-2552/aace8c}

\bibitem{kothe2019lsl}
Kothe, C.:
Lab Streaming Layer (LSL).
\url{https://github.com/sccn/labstreaminglayer} (2019)

\bibitem{gramfort2013mne}
Gramfort, A., et~al.:
MEG and EEG data analysis with MNE-Python.
Frontiers in Neuroscience \textbf{7}, 267 (2013)

\bibitem{kappenman2021erp}
Kappenman, E.S., Farrens, J.L., Zhang, W., Stewart, A.X., Luck, S.J.:
ERP CORE: An open resource for human event-related potential research.
NeuroImage \textbf{225}, 117465 (2021). \url{https://doi.org/10.1016/j.neuroimage.2020.117465}

\end{thebibliography}

\end{document}
